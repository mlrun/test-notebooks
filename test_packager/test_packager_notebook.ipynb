{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5babd3c-b2db-4cd2-9ff1-666987715169",
   "metadata": {},
   "source": [
    "# This notebook test full workflow while using MLRun packgers\n",
    "\n",
    "This notebook will test :\n",
    "\n",
    "1. Loging object to MLRun such as: `pd.DataFrame, np.ndarray, str and list`.\n",
    "2. Unpack `pd.DataFrame, np.ndarray, str and list` and compare them to the original values.\n",
    "3. Logging object to MLRun such as: `pd.DataFrame, np.ndarray, string, list` with non default artifact type and file format.\n",
    "4. Unpack outputs from step 3 and validate the expcted values are matched to the original \n",
    "5. Pack Custom packager that pack a zip file path to a zip file\n",
    "6. Unpack Custom packager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af111405-c54a-42b3-9e03-aa85eccd7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlrun[kfp18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e226790-72ab-4d35-9184-981faec48e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f05f06-2e80-4386-b18c-649291fd5463",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = mlrun.get_or_create_project(\"test-pack\",'./context',user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a30064-1313-43be-babc-6da4bdac0fdb",
   "metadata": {},
   "source": [
    "## 1.  Loging object to MLRun such as: `pd.DataFrame, np.array, string, list`\n",
    "\n",
    "Expcted logging result:\n",
    "* `pd.DataFrame` - as dataset artifact type and default parquet file\n",
    "* `np.nparray` - as artifact artifact type and default npy file\n",
    "* `str` - as a run result \n",
    "* `list` as a run result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4fd79-c9a8-4adc-9677-f4a9c4d53db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./context/generate-outputs.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_outputs():\n",
    "    df_true = pd.DataFrame(\n",
    "        data={\n",
    "            **{f\"column_{i}\": np.arange(0, 1000) for i in range(1, 10)},\n",
    "        },\n",
    "    ).set_index(keys=[\"column_7\", \"column_8\", \"column_9\"])\n",
    "\n",
    "    np_example = np.array(\n",
    "        [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\n",
    "    )\n",
    "\n",
    "    example_string = \"Example_String\"\n",
    "\n",
    "    example_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, \"A\"]\n",
    "    return df_true, np_example, example_string, example_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c922ad32-38b3-4e14-a8e3-14dea35e98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(\"./generate-outputs.py\",name='generate-outputs',kind='job',image='mlrun/mlrun',handler='generate_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edb280-4ded-4811-a087-f2527a26acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_run = project.run_function(\"generate-outputs\",returns=[\"df\",\"np_example\",\"example_string\",\"example_list\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35216cab-7e82-4638-ba4a-eebe09409dd1",
   "metadata": {},
   "source": [
    "**Validate Run Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73377cce-1f35-4071-9986-ca65bb8e3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs_run = project.get_store_resource(outputs_run.outputs[\"df\"])\n",
    "assert df_outputs_run.kind == 'dataset'\n",
    "assert df_outputs_run.target_path.endswith(\"parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7de39-c0f2-4080-99bf-cd58d04f69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outputs_run = project.get_store_resource(outputs_run.outputs[\"np_example\"])\n",
    "assert df_outputs_run.kind == 'artifact'\n",
    "assert df_outputs_run.target_path.endswith(\"npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96979372-5724-44b3-ae37-ac02ca8ddf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert outputs_run.outputs[\"example_string\"]=='Example_String'\n",
    "assert outputs_run.outputs[\"example_list\"]==[1, 2, 3, 4, 5, 6, 7, 8, 9, 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec2e3b-9c9e-4e64-b392-4f6aff806add",
   "metadata": {},
   "source": [
    "## 2. Unpack `pd.DataFrame, np.ndarray, str and list` and compare them to the original values.\n",
    "\n",
    "Expected result - \n",
    "* run the function without any assertion errors and validate the numpy and pandas are unpacked as expcted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e8b83-65ee-4886-80b1-19c41bb4a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./context/generate-inputs.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_inputs(np_example: np.ndarray, df: pd.DataFrame):\n",
    "    df_true = pd.DataFrame(\n",
    "        data={\n",
    "            **{f\"column_{i}\": np.arange(0, 1000) for i in range(1, 10)},\n",
    "        },\n",
    "    ).set_index(keys=[\"column_7\", \"column_8\", \"column_9\"])\n",
    "\n",
    "    # compare dataframe unpack\n",
    "    assert df_true.compare(df).shape == (0, 0)\n",
    "\n",
    "    # compare dataframe unpack\n",
    "    np_true = np.array(\n",
    "        [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\n",
    "    )\n",
    "    assert np.array_equal(np_true, np_example)\n",
    "\n",
    "    return \"OK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88864d39-b9ae-4675-ad3e-3bcadedbd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(\"./generate-inputs.py\",name='generate-inputs',kind='job',image='mlrun/mlrun',handler='generate_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f6ead9-d641-43ec-9919-200fada65927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = outputs_run.outputs[\"df\"]\n",
    "array_np = outputs_run.outputs[\"np_example\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef12de-6ada-4589-898c-2d893c0febae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_run = project.run_function(\"generate-inputs\",inputs={\"df\":df,\"np_example\":array_np},returns=[\"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f489576-84ae-45ef-a704-d71ce5b54b27",
   "metadata": {},
   "source": [
    "**Validate Run Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e9884-e914-4893-b230-5f5a2a53bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert inputs_run.outputs[\"state\"] == \"OK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0abccf-f6ef-4a04-91ff-f52ed20a7687",
   "metadata": {},
   "source": [
    "## 3. Logging object to MLRun such as: `pd.DataFrame, np.ndarray, string, list` with non default artifact type and file format.\n",
    "\n",
    "Excpected output result - \n",
    "\n",
    "* df_pkl as an artifact artifact type and pickle file\n",
    "* df_csv as an artifact artifact type and a csv file\n",
    "* np_csv as an artifact artifact type and a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a17c7-2e1d-4888-a34b-8dcf0ffef303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./context/generate-outputs-non-default.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "\n",
    "\n",
    "def generate_outputs():\n",
    "    df_true = pd.DataFrame(\n",
    "        data={\n",
    "            **{f\"column_{i}\": np.arange(0, 1000) for i in range(1, 10)},\n",
    "        },\n",
    "    ).set_index(keys=[\"column_7\", \"column_8\", \"column_9\"])\n",
    "\n",
    "    np_example = asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "\n",
    "    df_pkl = df_true\n",
    "    df_csv = df_true\n",
    "    np_csv = np_example\n",
    "    return df_pkl, df_csv, np_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fbab3-aa12-495e-9202-ad99a9ada712",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(\"./generate-outputs-non-default.py\",name='generate-outputs-non-default',kind='job',image='mlrun/mlrun',handler='generate_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b99c1-9d2c-4091-a7f4-bf95d9568c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_defualt_run = project.run_function('generate-outputs-non-default',returns=[\"df_pkl:object\",\n",
    "                                                                               {\"key\":\"df_csv\",\"artifact_type\":\"file\",\"file_format\":\"csv\"},\n",
    "                                                                               {\"key\":\"np_csv\",\"file_format\":\"csv\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c764e6e-574e-4f06-bf15-0c71048555c5",
   "metadata": {},
   "source": [
    "**Validate Run outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9bb27-8803-4ab5-919c-9f135afc05ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pkl_non_defualt_run = project.get_store_resource(non_defualt_run.outputs[\"df_pkl\"])\n",
    "assert df_pkl_non_defualt_run.kind == 'artifact'\n",
    "assert df_pkl_non_defualt_run.target_path.endswith(\"pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82fc1a-996c-44ef-a9b9-cd5104a89e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_non_defualt_run = project.get_store_resource(non_defualt_run.outputs[\"df_csv\"])\n",
    "assert df_csv_non_defualt_run.kind == 'artifact'\n",
    "assert df_csv_non_defualt_run.target_path.endswith(\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e7ae2-7a04-429c-af76-38b65cf2a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_csv_non_defualt_run = project.get_store_resource(non_defualt_run.outputs[\"np_csv\"])\n",
    "assert np_csv_non_defualt_run.kind == 'artifact'\n",
    "assert np_csv_non_defualt_run.target_path.endswith(\"csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d8f3f-9d3b-496c-b0fb-34802dd758c6",
   "metadata": {},
   "source": [
    "## 4. Unpack outputs from step 3 and validate the expcted values are matched to the original \n",
    "\n",
    "Excpted result -\n",
    "* run without assertion errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f15cd-0b21-4347-bdf4-bda2d481d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./context/generate-inputs-non-defaults.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "\n",
    "\n",
    "def generate_inputs(df_pkl: pd.DataFrame, df_csv: pd.DataFrame, np_csv: np.ndarray):\n",
    "    df_true = pd.DataFrame(\n",
    "        data={\n",
    "            **{f\"column_{i}\": np.arange(0, 1000) for i in range(1, 10)},\n",
    "        },\n",
    "    ).set_index(keys=[\"column_7\", \"column_8\", \"column_9\"])\n",
    "    # compare dataframe unpack\n",
    "    assert df_true.compare(df_pkl).shape == (0, 0)\n",
    "    assert df_true.compare(df_csv).shape == (0, 0)\n",
    "    # compare dataframe unpack\n",
    "    np_true = asarray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "    assert np.array_equal(np_true, np_csv)\n",
    "\n",
    "    return \"OK\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b13be-38a9-4640-aec0-f54c4688aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pkl = non_defualt_run.outputs[\"df_pkl\"]\n",
    "df_csv = non_defualt_run.outputs[\"df_csv\"]\n",
    "np_csv = non_defualt_run.outputs[\"np_csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed2eb5-5c44-41a9-b727-d3e95a3ee54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(\"./generate-inputs-non-defaults.py\",name='generate-inputs-non-defaults',kind='job',image='mlrun/mlrun',handler='generate_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43691df0-1035-4b5c-a2b8-473c31b9bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_run_non_defualt = project.run_function(\"generate-inputs-non-defaults\",inputs={\"df_pkl\":df_pkl,\"df_csv\":df_csv,\"np_csv\":np_csv},returns=[\"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c95f7c-1c9d-40db-9417-db0af6654925",
   "metadata": {},
   "source": [
    "## 5. Run packing and unpacking in pipeline \n",
    "\n",
    "Expcted result - status is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c4751-7acc-4e5e-a65f-239531019801",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./context/workflow.py\n",
    "import mlrun\n",
    "from kfp import dsl\n",
    "from mlrun import get_or_create_ctx\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"test-packager-pipeline\",\n",
    "    description=\"predicting stock prices using yahoo api with sentiment analysis\"\n",
    ")\n",
    "\n",
    "def kfpipeline():\n",
    "\n",
    "    ctx = get_or_create_ctx(name='kfp-context')\n",
    "\n",
    "    kfp_project = mlrun.get_current_project()\n",
    "\n",
    "    kfp_generate_outputs_run = mlrun.run_function(\"generate-outputs\",\n",
    "                                              returns=[\"df\",\"np_example\",\"example_string\",\"example_list\"])\n",
    "\n",
    "    kfp_project.run_function(\"generate-inputs\", inputs={\"df\":kfp_generate_outputs_run.outputs[\"df\"], \"np_example\":kfp_generate_outputs_run.outputs[\"np_example\"]}, returns=[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c38823-0e70-4b57-8415-c05b36c6348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file:\n",
    "workflow_name = \"test-packager-workflow\"\n",
    "project.set_workflow(name=workflow_name, workflow_path=\"workflow.py\")\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d596a5f-d458-42fe-a3f7-ba7596017294",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run(workflow_name,\n",
    "            watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5d194-9782-453e-ac50-e24c4d4547a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Pack Custom packager that pack a zip file path to a zip file\n",
    "\n",
    "Expcted result -\n",
    "* to pack a string as an artifact type artifact and as a zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d8332-a510-48a7-b838-3e6034d0f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./custom_pack/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0d5349-02de-4ba6-8853-b54d2986285b",
   "metadata": {},
   "source": [
    "Writing custome object file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8253d-f11c-4e92-a205-69e8daa22186",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./custom_pack/custom.py\n",
    "import os\n",
    "import tempfile\n",
    "import pathlib\n",
    "from typing import Tuple\n",
    "\n",
    "from mlrun import ArtifactType\n",
    "from mlrun.artifacts import Artifact\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.errors import MLRunInvalidArgumentError\n",
    "from mlrun.package import DefaultPackager\n",
    "from mlrun.package.utils import DEFAULT_ARCHIVE_FORMAT, ArchiveSupportedFormat\n",
    "\n",
    "\n",
    "class StringPackager(DefaultPackager):\n",
    "    \"\"\"\n",
    "    ``builtins.str`` packager.\n",
    "    \"\"\"\n",
    "\n",
    "    PACKABLE_OBJECT_TYPE = str\n",
    "    DEFAULT_PACKING_ARTIFACT_TYPE = ArtifactType.FILE\n",
    "    DEFAULT_UNPACKING_ARTIFACT_TYPE = ArtifactType.PATH\n",
    "\n",
    "    def pack_file(\n",
    "        self, obj: str, key: str, archive_format: str = DEFAULT_ARCHIVE_FORMAT\n",
    "    ) -> Tuple[Artifact, dict]:\n",
    "        \"\"\"\n",
    "        Pack a zip value content (pack the file or directory in that path).\n",
    "\n",
    "        :param obj:            The zip object to pack.\n",
    "        :param key:            The key to use for the artifact.\n",
    "        :param archive_format: The archive format to use in case the path is of a directory. Default is zip.\n",
    "\n",
    "        :return: The packed artifact and instructions.\n",
    "        \"\"\"\n",
    "        # Proceed by path type (file or directory):\n",
    "        if os.path.isfile(obj):\n",
    "            # Create the artifact:\n",
    "            artifact = Artifact(key=key, src_path=os.path.abspath(obj))\n",
    "            instructions = {\"archive_format\": \"zip\", \"is_directory\": True}\n",
    "        else:\n",
    "            raise MLRunInvalidArgumentError(\n",
    "                f\"The given path is not a file nor a directory: '{obj}'\"\n",
    "            )\n",
    "\n",
    "        return artifact, instructions\n",
    "\n",
    "    def unpack_file(\n",
    "        self, data_item: DataItem, is_directory: bool = False, archive_format: str = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Unpack a data item representing a path string. If the path is of a file, the file is downloaded to a local\n",
    "        temporary directory and its path is returned. If the path is of a directory, the archive is extracted and the\n",
    "        directory path extracted is returned.\n",
    "\n",
    "        :param data_item:      The data item to unpack.\n",
    "        :param is_directory:   Whether the path should be treated as a file or a directory. Files (even archives like\n",
    "                               zip) won't be extracted.\n",
    "        :param archive_format: The archive format to use in case the path is of a directory. Default is None - will be\n",
    "                               read by the archive file extension.\n",
    "\n",
    "        :return: The unpacked string.\n",
    "        \"\"\"\n",
    "        # Get the file to a local temporary directory:\n",
    "        path = data_item.local()\n",
    "\n",
    "        # Mark the downloaded file for future clear:\n",
    "        self.add_future_clearing_path(path=path)\n",
    "\n",
    "        # If it's not a directory, return the file path. Otherwise, it should be extracted according to the archive\n",
    "        # format:\n",
    "        if not is_directory:\n",
    "            return path\n",
    "\n",
    "        # Get the archive format by the file extension:\n",
    "        if archive_format is None:\n",
    "            archive_format = ArchiveSupportedFormat.match_format(path=path)\n",
    "        if archive_format is None:\n",
    "            raise MLRunInvalidArgumentError(\n",
    "                f\"Archive format of {data_item.key} ('{''.join(pathlib.Path(path).suffixes)}') is not supported. \"\n",
    "                f\"Supported formats are: {' '.join(ArchiveSupportedFormat.get_all_formats())}\"\n",
    "            )\n",
    "\n",
    "        # Extract the archive:\n",
    "        archiver = ArchiveSupportedFormat.get_format_handler(fmt=archive_format)\n",
    "        directory_path = archiver.extract_archive(\n",
    "            archive_path=path, output_path=os.path.dirname(path)\n",
    "        )\n",
    "\n",
    "        # Mark the extracted content for future clear:\n",
    "        self.add_future_clearing_path(path=directory_path)\n",
    "\n",
    "        # Return the extracted directory path:\n",
    "        return directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d0717-7978-4e1d-8ac0-ae78c300e904",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./custom_pack/test-custom.py\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from custom import StringPackager\n",
    "\n",
    "\n",
    "def func_custom():\n",
    "    os.makedirs(\"./files/\")\n",
    "    with open(\"./files/test_1.txt\", \"w\") as file:\n",
    "        file.write(\"file1\")\n",
    "        file.close()\n",
    "\n",
    "    with open(\"./files/test_2.txt\", \"w\") as file:\n",
    "        file.write(\"file2\")\n",
    "        file.close()\n",
    "\n",
    "    with open(\"./files/test_3.txt\", \"w\") as file:\n",
    "        file.write(\"file3\")\n",
    "        file.close()\n",
    "\n",
    "    shutil.make_archive(\"test\", \"zip\", \"./files/\")\n",
    "    return \"./test.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd47cdc-d1e5-4ea4-81e6-9b450f5e2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./custom_pack/test-custom-unpack.py\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from custom import StringPackager\n",
    "\n",
    "from mlrun import ArtifactType\n",
    "\n",
    "\n",
    "def func_custom(zip_file: str):\n",
    "    print(zip_file)\n",
    "    with open(f\"{zip_file}/test_1.txt\", \"r\") as file:\n",
    "        read = file.read()\n",
    "        assert read == \"file1\"\n",
    "        file.close()\n",
    "\n",
    "    with open(f\"{zip_file}/test_2.txt\", \"r\") as file:\n",
    "        read = file.read()\n",
    "        assert read == \"file2\"\n",
    "        file.close()\n",
    "\n",
    "    with open(f\"{zip_file}/test_3.txt\", \"r\") as file:\n",
    "        read = file.read()\n",
    "        assert read == \"file3\"\n",
    "        file.close()\n",
    "\n",
    "    return \"Completed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71fe3c-9e89-48e6-90d2-ebd584af0484",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.add_custom_packager(packager=\"custom.StringPackager\",is_mandatory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef896d-10cb-4afd-91ad-a322302bbdba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('test','zip','./custom_pack/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aaa567-06a6-4957-8e48-c779125e065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_art = project.log_artifact(\"source-zip\",local_path='./test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593079a7-ae14-4e95-bce4-26c0e55388dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_source(source_art.target_path,pull_at_runtime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80729f45-2746-4d54-beca-e425db27a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb2b87-6792-474d-9812-dc1e39619a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = project.set_function(\"./test-custom.py\",name=\"test-custom\",kind='job',image='mlrun/mlrun',handler='func_custom',with_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fec00-41d9-48ed-886e-0e36e4102510",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func = func.run(returns=[\"test_zip:file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b768169-4be1-448d-9cf5-a6ec5f6e5788",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Unpack Custom packager\n",
    "Expcted result -\n",
    "* unpack the zip file to the temp folder and check the file content and run without assert issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ec383-43c8-42d6-937c-877f46096ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "func = project.set_function(\"./test-custom-unpack.py\",name=\"test-custom-unpack\",kind='job',image='mlrun/mlrun',handler='func_custom',with_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f626e-1bb3-4da3-a4f9-a0df0090ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_zip = test_func.outputs[\"test_zip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7f913-aa2f-4a8f-a09c-a247c2a49b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "func.run(inputs={\"zip_file\":input_zip},returns=[\"State\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0366e-797b-4267-b856-1388c84d3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = mlrun.get_run_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc092f7d-df4c-4855-bb44-c2811444de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.delete_project(name=project.name,deletion_strategy='cascade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463fb5e-6807-4640-a42e-a5711bee4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./context/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c22c925-0599-4c31-92cc-5dd30a448186",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('./custom_pack/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba2f45-f722-4110-934d-d36920b49628",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./test.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
