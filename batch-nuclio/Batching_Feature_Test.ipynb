{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d837ed0a-a998-460d-96a1-e5a0f2009814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Batching\n",
    "\n",
    "This notebook sends a controlled number of HTTP events to a Nuclio function that is configured for batching and then validates how the function actually batched and processed them. It collects all responses, builds a pandas DataFrame, and checks that the first batch reached the configured batch size, was handled together, and got the same end time. It then verifies that the remaining event was flushed in a second batch and that this second batch happened after the batching timeout window. The notebook also prints the batch sizes and per worker distribution so you can see how Nuclio spread the work across workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3992001a-22ff-4e4a-b084-6ba8e8fb3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45102d96-2f45-4cc2-8770-1ec8e78a571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-11-09 13:05:11,303 [info] Project loaded successfully: {\"project_name\":\"batching-nuclio-guyl\"}\n"
     ]
    }
   ],
   "source": [
    "project = mlrun.get_or_create_project(\"batching-nuclio\",user_project=True,allow_cross_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c89686-1695-441e-8692-1815fa1aaaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting batching-nuclio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile batching-nuclio.py\n",
    "import nuclio_sdk\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "BATCH_NUM = 0  # start from 0\n",
    "\n",
    "def handler(context, batch: list[nuclio_sdk.Event]):\n",
    "    global BATCH_NUM\n",
    "    context.logger.info_with(\"Got batched event\", size=len(batch))\n",
    "\n",
    "    BATCH_NUM += 1   # each batch gets the next number\n",
    "    this_batch_num = BATCH_NUM\n",
    "\n",
    "    response_msg = process_batch(batch)\n",
    "    responses = []\n",
    "\n",
    "    for item in batch:\n",
    "        body = item.body\n",
    "        try:\n",
    "            if isinstance(body, bytes):\n",
    "                body = body.decode(\"utf-8\")\n",
    "            parsed = json.loads(body)\n",
    "        except Exception:\n",
    "            parsed = body\n",
    "\n",
    "        resp_body = {\n",
    "            \"body\": parsed,\n",
    "            \"batch_num\": this_batch_num,\n",
    "            \"batch_ts\": datetime.now().isoformat(timespec=\"milliseconds\"),\n",
    "            \"msg\": response_msg,\n",
    "            \"worker_id\": context.worker_id,\n",
    "            \"end_time\": datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        responses.append(\n",
    "            nuclio_sdk.Response(\n",
    "                body=json.dumps(resp_body),\n",
    "                headers={\"Content-Type\": \"application/json\"},\n",
    "                content_type=\"application/json\",\n",
    "                status_code=200,\n",
    "                event_id=item.id,\n",
    "            )\n",
    "        )\n",
    "    return responses\n",
    "\n",
    "def process_batch(event_list: list[nuclio_sdk.Event]):\n",
    "    return \"hello\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212e68b-c38e-40d2-ac4c-eb005321d8f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Batch Size #1\n",
    " Testing with the following parameters: `11 events`, `batch size 10`, `1 workers`, `timeout 5s`, test 11 events process 10 in one batch and wait 5 seconds for the 11th event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990db452-caf0-4a90-940f-554a098ab5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclio_batch2 = project.set_function(func=\"batching-nuclio.py\",name=\"batching-nuclio\",image=\"mlrun/mlrun\",kind=\"nuclio\")\n",
    "nuclio_batch2.spec.handler = \"batching-nuclio:handler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb0b0dfc-f892-4400-8e03-4f474209546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-11-09 13:05:11,329 [warning] Adding HTTP trigger despite the default HTTP trigger creation being disabled\n"
     ]
    }
   ],
   "source": [
    "nuclio_batch2.with_http(workers=1, worker_timeout=30)\n",
    "nuclio_batch2.spec.max_replicas = 1\n",
    "nuclio_batch2.spec.config[\"spec.triggers.http\"][\"batch\"]={\"mode\": \"enable\",\"batchSize\":10, \"timeout\":\"5s\",\"eventTimeout\": \"60s\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdbe7f2d-6f70-42cd-b355-400739ef73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2025-11-09 13:05:11,338 [info] Starting remote function deploy\n",
      "2025-11-09 13:05:11  (info) Deploying function\n",
      "2025-11-09 13:05:11  (info) Building\n",
      "2025-11-09 13:05:11  (info) Staging files and preparing base images\n",
      "2025-11-09 13:05:11  (warn) Using user provided base image, runtime interpreter version is provided by the base image\n",
      "2025-11-09 13:05:11  (info) Building processor image\n",
      "2025-11-09 13:06:17  (info) Build complete\n",
      "2025-11-09 13:06:25  (info) Function deploy complete\n",
      "> 2025-11-09 13:06:32,232 [info] Successfully deployed function: {\"external_invocation_urls\":[\"batching-nuclio-guyl-batching-nuclio.default-tenant.app.cust-cs-il.iguazio-cd0.com/\"],\"internal_invocation_urls\":[\"nuclio-batching-nuclio-guyl-batching-nuclio.default-tenant.svc.cluster.local:8080\"]}\n",
      "URL: http://batching-nuclio-guyl-batching-nuclio.default-tenant.app.cust-cs-il.iguazio-cd0.com/\n"
     ]
    }
   ],
   "source": [
    "addr = nuclio_batch2.deploy()\n",
    "print(\"URL:\", addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c124a66-ef6b-474a-b250-d4f3d900fcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  {5.03502}\n",
      "âœ… batching timing test passed\n",
      "     i  status  batch_num                    send_at  \\\n",
      "0    0     200          1 2025-11-09 13:06:32.308469   \n",
      "1    1     200          1 2025-11-09 13:06:32.308974   \n",
      "2    2     200          1 2025-11-09 13:06:32.309344   \n",
      "3    3     200          1 2025-11-09 13:06:32.309766   \n",
      "4    4     200          1 2025-11-09 13:06:32.319822   \n",
      "5    5     200          1 2025-11-09 13:06:32.322943   \n",
      "6    6     200          1 2025-11-09 13:06:32.323659   \n",
      "7    7     200          1 2025-11-09 13:06:32.335908   \n",
      "8    8     200          1 2025-11-09 13:06:32.339862   \n",
      "9    9     200          1 2025-11-09 13:06:32.349957   \n",
      "10  10     200          2 2025-11-09 13:06:32.410415   \n",
      "\n",
      "                     end_time           end_time_0_1s  \n",
      "0  2025-11-09 13:06:32.408184 2025-11-09 13:06:32.400  \n",
      "1  2025-11-09 13:06:32.408143 2025-11-09 13:06:32.400  \n",
      "2  2025-11-09 13:06:32.408170 2025-11-09 13:06:32.400  \n",
      "3  2025-11-09 13:06:32.408195 2025-11-09 13:06:32.400  \n",
      "4  2025-11-09 13:06:32.408205 2025-11-09 13:06:32.400  \n",
      "5  2025-11-09 13:06:32.408242 2025-11-09 13:06:32.400  \n",
      "6  2025-11-09 13:06:32.408214 2025-11-09 13:06:32.400  \n",
      "7  2025-11-09 13:06:32.408233 2025-11-09 13:06:32.400  \n",
      "8  2025-11-09 13:06:32.408224 2025-11-09 13:06:32.400  \n",
      "9  2025-11-09 13:06:32.408254 2025-11-09 13:06:32.400  \n",
      "10 2025-11-09 13:06:37.443163 2025-11-09 13:06:37.400  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "URL = addr\n",
    "NUM_EVENTS = 11\n",
    "BATCH_SIZE = 10\n",
    "EXPECTED_TIMEOUT = 5      # seconds\n",
    "TIME_TOLERANCE = 1.0      # seconds, to allow for scheduler jitter\n",
    "\n",
    "def fetch(i, timeout=20):\n",
    "    payload = {\"test\": i, \"send_at\": datetime.now().isoformat()}\n",
    "    r = requests.post(URL, json=payload, timeout=timeout)\n",
    "    return i, r.status_code, r.text\n",
    "\n",
    "# send events\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=10) as ex:\n",
    "    futs = [ex.submit(fetch, i) for i in range(NUM_EVENTS)]\n",
    "    for f in as_completed(futs):\n",
    "        results.append(f.result())\n",
    "\n",
    "# build df\n",
    "rows = []\n",
    "for i, status, body in results:\n",
    "    data = json.loads(body)\n",
    "    sent_payload = data[\"body\"]\n",
    "    if isinstance(sent_payload, str):\n",
    "        try:\n",
    "            sent_payload = json.loads(sent_payload)\n",
    "        except Exception:\n",
    "            sent_payload = {}\n",
    "    rows.append(\n",
    "        {\n",
    "            \"i\": i,\n",
    "            \"status\": status,\n",
    "            \"batch_num\": data[\"batch_num\"],\n",
    "            \"send_at\": sent_payload.get(\"send_at\"),\n",
    "            \"end_time\": data[\"end_time\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"i\").reset_index(drop=True)\n",
    "\n",
    "# Verify that the number of responses matches the number of events sent\n",
    "assert len(df) == NUM_EVENTS, f\"Expected {NUM_EVENTS}, got {len(df)}\"\n",
    "assert (df[\"status\"] == 200).all(), f\"Non 200 rows: {df[df['status'] != 200]}\"\n",
    "\n",
    "# Convert time fields to datetime objects and normalize end_time to 0.1-second precision\n",
    "# This allows consistent comparison of timing between events.\n",
    "df[\"send_at\"] = pd.to_datetime(df[\"send_at\"])\n",
    "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"])\n",
    "df[\"end_time_0_1s\"] = df[\"end_time\"].dt.round(\"100ms\")\n",
    "\n",
    "# 1. Validate the first batch behavior\n",
    "# Confirm that the first batch reached exactly the configured batch size\n",
    "# and that the first 10 (batch size) rows all belong to the same batch number.\n",
    "\n",
    "first_batch_num = df.loc[0, \"batch_num\"]\n",
    "first_batch_df = df[df[\"batch_num\"] == first_batch_num].sort_values(\"i\")\n",
    "\n",
    "assert len(first_batch_df) == BATCH_SIZE, (\n",
    "    f\"First batch size is {len(first_batch_df)}, expected {BATCH_SIZE}\"\n",
    ")\n",
    "\n",
    "assert (df.loc[:BATCH_SIZE-1, \"batch_num\"] == first_batch_num).all(), \\\n",
    "    f\"First {BATCH_SIZE} rows are not in the same batch\"\n",
    "\n",
    "# Ensure all first-batch events were processed together,\n",
    "# by confirming they share the same rounded end_time.\n",
    "first_batch_times = first_batch_df[\"end_time_0_1s\"].unique()\n",
    "assert len(first_batch_times) == 1, f\"First batch has multiple times: {first_batch_times}\"\n",
    "\n",
    "# 2. Validate the second batch trigger\n",
    "# Check that the remaining event was processed in a separate batch\n",
    "# and that this batch has a distinct batch number and correct size 1.\n",
    "second_row = df.loc[BATCH_SIZE]\n",
    "second_batch_num = second_row[\"batch_num\"]\n",
    "assert second_batch_num != first_batch_num, \\\n",
    "    f\"Second batch row has same batch_num as first: {second_batch_num}\"\n",
    "\n",
    "# second batch should have the remaining events\n",
    "second_batch_df = df[df[\"batch_num\"] == second_batch_num]\n",
    "expected_second_batch_size = NUM_EVENTS - BATCH_SIZE\n",
    "assert len(second_batch_df) == expected_second_batch_size, (\n",
    "    f\"Second batch size is {len(second_batch_df)}, expected {expected_second_batch_size}\"\n",
    ")\n",
    "\n",
    "# 3. Verify batching timeout behavior\n",
    "# The second batch should be processed after approximately the batching timeout period.\n",
    "# Measure the gap between the first and second batch end_time values.\n",
    "first_batch_time = first_batch_df[\"end_time\"].min()\n",
    "second_batch_time = second_batch_df[\"end_time\"].min()\n",
    "diff = (second_batch_time - first_batch_time).total_seconds()\n",
    "\n",
    "assert abs(diff - EXPECTED_TIMEOUT) <= TIME_TOLERANCE, (\n",
    "    f\"Second batch did not fire near timeout. \"\n",
    "    f\"diff={diff:.2f}s, expected about {EXPECTED_TIMEOUT}s\"\n",
    ")\n",
    "\n",
    "# 4. Ensure the batches were distinct in time\n",
    "# Confirm that the rounded end_time values for the first and second batch differ,\n",
    "# proving they were executed as separate batch windows.\n",
    "assert second_batch_df[\"end_time_0_1s\"].iloc[0] != first_batch_times[0], \\\n",
    "    \"Second batch rounded time equals first batch time\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "6064678a-2129-4009-baf2-4a4dd8b2971d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
