{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8def168",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training A `TensorFlow.Keras` Classifier With And Without `Horovod`\n",
    "\n",
    "This test uses MNIST dataset to train a model using TensorFlow.Keras with and without Horovod. Later it will verify that:\n",
    "\n",
    "  * The accuracy was not damaged in Horovod.\n",
    "  * The Horovod run was faster (only possible on big data). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15032737",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## General Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e190f156",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of epochs to train (to increase the training time without increasing the memory usage):\n",
    "N_EPOCHS = 4\n",
    "\n",
    "# Number of ranks (horovod workers) to deploy for the open mpi job:\n",
    "N_RANKS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869f13d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Training Code\n",
    "\n",
    "1. Get the MNIST data from `tensorflow.keras.datasets`.\n",
    "2. Initialize a model.\n",
    "3. Run training on the training set with validation on the testing set.\n",
    "\n",
    "Accuracy score will be logged as a result as part of MLRun auto-logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1645ea6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile func.py\n",
    "from typing import Tuple\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import mlrun\n",
    "import mlrun.frameworks.tf_keras as mlrun_tf_keras\n",
    "\n",
    "\n",
    "def get_datasets(batch_size: int) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "    # Download the data:\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Initialize tensorflow datasets:\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "    test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
    "    \n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "def get_model() -> tf.keras.Model:\n",
    "    # Build the model architecture:\n",
    "    inputs = tf.keras.Input(shape=(28, 28))\n",
    "    x = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Initialize a model:\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "@mlrun.handler(outputs=[\"time\"])\n",
    "def train(context: mlrun.MLClientCtx, n_epochs: int):\n",
    "    # Start the timer:\n",
    "    run_time = time.time()\n",
    "    \n",
    "    # Get the data:\n",
    "    batch_size = 32\n",
    "    train_set, test_set = get_datasets(batch_size=batch_size)\n",
    "\n",
    "    # Get the model:\n",
    "    model = get_model()\n",
    "    \n",
    "    # Apply MLRun:\n",
    "    mlrun_tf_keras.apply_mlrun(model=model, context=context)\n",
    "\n",
    "    # Compile the model:\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.1, momentum=0.9),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Train:\n",
    "    model.fit(\n",
    "        train_set,\n",
    "        validation_data=test_set,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=len(train_set) // batch_size,\n",
    "    )\n",
    "    run_time = time.time() - run_time\n",
    "    \n",
    "    return run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a946442",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Create a Project\n",
    "\n",
    "1. Create the MLRun project.\n",
    "2. Create an MLRun function of the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a5d55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa8c59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the project:\n",
    "project = mlrun.get_or_create_project(name=\"horovod-tensorflow-test\", context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ebfc4-5ed6-4ddf-a527-789bebb78204",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create the job function:\n",
    "# TODO: bump to 2.18.1 after ML-10271 fix\n",
    "job_function = project.set_function(\"./func.py\", name=\"train_job\", kind=\"job\", image=\"mlrun/mlrun\", handler=\"train\", requirements=[\"tensorflow==2.15.1\"])\n",
    "job_function.apply(mlrun.auto_mount())\n",
    "job_function.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b573364-6a54-45f4-bbe1-bf5d4149788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.build_image(image=f'.tfimage',\n",
    "                    base_image='mlrun/mlrun',\n",
    "                    requirements=['tensorflow==2.15.1'],\n",
    "                    overwrite_build_params=True,\n",
    "                    set_as_default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1b77f-f0cd-4272-bd0b-b882bdf3d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RANKS = 4  # adjust to number of workers you want\n",
    "\n",
    "mpijob_function = project.set_function(\n",
    "    \"./func.py\",\n",
    "    name=\"train_mpijob\",\n",
    "    kind=\"mpijob\",\n",
    "    image=\".tfimage\",\n",
    "    handler=\"train\",\n",
    ")\n",
    "\n",
    "mpijob_function.apply(mlrun.auto_mount())\n",
    "mpijob_function.spec.replicas = N_RANKS\n",
    "\n",
    "builder_env = {\n",
    "    'HOROVOD_WITH_MPI': '1',\n",
    "    'HOROVOD_WITH_TENSORFLOW': '1',\n",
    "    'HOROVOD_WITHOUT_MLX': '1',\n",
    "    'HOROVOD_WITHOUT_PYTORCH': '1',\n",
    "    'HOROVOD_WITHOUT_MXNET': '1',\n",
    "    'HOROVOD_WITHOUT_GLOO': '1',\n",
    "    'HOROVOD_WITHOUT_XLA': '1',\n",
    "}\n",
    "\n",
    "commands = [\n",
    "    'apt update --fix-missing \\\n",
    "    && apt upgrade -y \\\n",
    "    && apt install -y \\\n",
    "         llvm-dev \\\n",
    "         build-essential \\\n",
    "         cmake \\\n",
    "         gcc-12 g++-12 \\\n",
    "    && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-12 60 \\\n",
    "    && update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-12 60 \\\n",
    "    && update-alternatives --set gcc /usr/bin/gcc-12 \\\n",
    "    && update-alternatives --set g++ /usr/bin/g++-12 \\\n",
    "    && apt clean \\\n",
    "    && rm -rf /var/lib/apt/lists/*',\n",
    "    'pip install horovod==0.28.1',\n",
    "    'pip install typing_extensions==4.14.1'\n",
    "]\n",
    "\n",
    "\n",
    "mpijob_function.spec.build.commands=commands\n",
    "mpijob_function.deploy(builder_env=builder_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e8ae7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Run As A Job\n",
    "\n",
    "Run the training as a `job` and storing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83557d09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run as a job:\n",
    "job_run = job_function.run(\n",
    "    name=\"training_job\",\n",
    "    output_path=\"/tmp/\",\n",
    "    params={\n",
    "        \"n_epochs\": N_EPOCHS,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Store results:\n",
    "job_time = job_run.status.results['time']\n",
    "job_accuracy = job_run.status.results['validation_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4da6ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Run As a MPIJob\n",
    "\n",
    "Run the training as a `mpijob` and storing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d215f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Run as a mpijob:\n",
    "mpijob_run = mpijob_function.run(\n",
    "    name=\"training_mpijob\",\n",
    "    output_path=\"/tmp/\",\n",
    "    params={\n",
    "        \"n_epochs\": N_EPOCHS,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Store results:\n",
    "mpijob_time = mpijob_run.status.results['time']\n",
    "mpijob_accuracy = mpijob_run.status.results['validation_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51588842",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Compare Runtimes\n",
    "\n",
    "1. Print a summary message.\n",
    "2. Verify that:\n",
    "  * The mpijob run took less time (only in stronger machines). \n",
    "  * The accuracy value is equal between the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e56bde",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Delete the MLRun project:\n",
    "mlrun.get_run_db().delete_project(name=project.name, deletion_strategy=\"cascading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ddd75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Print the test's collected results:\n",
    "print(\n",
    "    f\"Job:\\n\" \n",
    "    f\"\\t{'%.2f' % job_time} Seconds\\n\"\n",
    "    f\"\\tAccuracy: {job_accuracy}\"\n",
    ")\n",
    "print(\n",
    "    f\"Open MPI Job (Horovod):\\n\"\n",
    "    f\"\\t{'%.2f' % mpijob_time} Seconds\\n\"\n",
    "    f\"\\tAccuracy: {mpijob_accuracy}\\n\"\n",
    ")\n",
    "\n",
    "# Verification: (Only possible to test on a stronger machine (requires big data and longer training)\n",
    "# assert mpijob_time < job_time\n",
    "# assert np.isclose(job_accuracy, mpijob_accuracy, atol=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun",
   "language": "python",
   "name": "mlrun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
